# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
# Allow all crawlers (Google, Bing, etc.)
User-agent: *
Disallow:

# Explicitly allow Facebook crawlers (for link preview)
User-agent: facebookexternalhit
Allow: /

User-agent: facebookexternalhit/1.1
Allow: /

User-agent: facebot
Allow: /
